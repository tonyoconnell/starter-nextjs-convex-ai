# Story 3.4: Specialized Worker Infrastructure & Redis Integration

## Status

Ready

## Story

**As a** developer,
**I want** a robust Cloudflare Worker + Upstash Redis logging infrastructure that handles high-frequency log ingestion without race conditions,
**so that** I can reliably capture logs from all systems during development.

## Acceptance Criteria

1. A specialized Cloudflare Worker (`apps/workers/log-ingestion/`) handles log ingestion with built-in rate limiting and batching.
2. Upstash Redis integration provides cost-effective short-term log storage with 1-hour TTL (~$2/month vs $10).
3. Multi-system support ingests logs from browser, Convex functions, and other Cloudflare Workers with automatic system detection.
4. Worker-based rate limiting eliminates database race conditions while preserving trace correlation capabilities.
5. **Integration**: Monorepo deployment patterns with Turbo for coordinated development and deployment workflows.
6. **Migration**: Complete removal of broken Convex logging tables and files with fresh start approach.

## Estimation & Planning

### Story Points

13

### Estimated Complexity

High

### Estimated Time

4-5 days

### Risk Level

High

## Tasks / Subtasks

- [ ] Task 1: Create Cloudflare Worker Infrastructure (AC: 1, 5)
  - [ ] Set up `apps/workers/log-ingestion/` directory structure
  - [ ] Implement main worker entry point with HTTP request handling
  - [ ] Create rate limiting module with per-trace and global quotas
  - [ ] Add system detection logic (browser/convex/worker) based on headers
  - [ ] Implement batch buffering for efficient Redis writes
  - [ ] Configure wrangler.toml for production and development environments

- [ ] Task 2: Upstash Redis Integration (AC: 2)
  - [ ] Set up Upstash Redis client with REST API integration
  - [ ] Implement Redis data structure with 1-hour TTL for log entries
  - [ ] Create log storage functions with trace_id key patterns
  - [ ] Add cost monitoring and usage tracking
  - [ ] Implement Redis connection error handling and fallbacks

- [ ] Task 3: Multi-System Log Ingestion (AC: 3)
  - [ ] Update browser console override to use Worker endpoint
  - [ ] Create Convex internal action for sending logs to Worker
  - [ ] Implement automatic system detection and tagging
  - [ ] Add CORS configuration for multi-origin requests
  - [ ] Test log ingestion from all three system types

- [ ] Task 4: Worker-Based Rate Limiting (AC: 4)
  - [ ] Implement distributed rate limiting using Worker memory or Durable Objects
  - [ ] Create rate limit quotas: 40% browser, 30% worker, 30% backend
  - [ ] Add per-trace rate limiting (100 logs/hour per trace)
  - [ ] Implement global rate limiting (1000 logs/hour total)
  - [ ] Preserve trace correlation capabilities across rate-limited systems

- [ ] Task 5: Monorepo Integration & Deployment (AC: 5)
  - [ ] Add Worker deployment scripts to root package.json
  - [ ] Configure Turbo tasks for Worker development and deployment
  - [ ] Set up local development workflow with parallel services
  - [ ] Create production deployment process for Workers
  - [ ] Test coordinated deployment of frontend + backend + workers

- [ ] Task 6: Convex System Migration & Cleanup (AC: 6)
  - [ ] Remove broken Convex logging tables from schema.ts
  - [ ] Delete obsolete logging files (rateLimiter.ts, logCorrelation.ts, etc.)
  - [ ] Clean up Story 3.2/3.3 admin components that reference removed functions
  - [ ] Update existing log ingestion points to use Worker endpoints
  - [ ] Verify complete removal of old logging system

## Documentation Impact Assessment

**Architectural Patterns Established:**

- Cloudflare Worker microservice pattern for high-frequency operations
- Redis-based short-term storage architecture with automatic expiry
- Multi-system log ingestion with automatic source detection
- Monorepo coordination between Next.js, Convex, and Workers
- Cost-optimized logging architecture (~80% cost reduction)

**Documentation Updates Needed:**

- Add Worker infrastructure to `docs/architecture/source-tree.md`
- Update deployment patterns in `docs/architecture/infrastructure-and-deployment.md`
- Create Worker patterns in `docs/patterns/backend-patterns.md`
- Update cost analysis in logging system documentation

**Knowledge Capture:**

- Cloudflare Worker development patterns in monorepo
- Upstash Redis integration and cost optimization strategies
- Multi-system logging coordination patterns
- Worker-based rate limiting alternatives to database solutions

**Examples to Create:**

- Cloudflare Worker setup and deployment example
- Redis integration patterns for short-term storage
- Multi-system logging architecture implementation

## Dev Notes

### Previous Story Insights

From Story 3.3 completion, the existing logging system has:

- **Critical Issues Identified**:
  - Race conditions in Convex database writes during high-frequency logging
  - High cost (~$10/month) due to database writes for every log entry
  - Reliability issues with burst log traffic during development
  - Complex rate limiting causing performance bottlenecks

- **Components to Preserve**:
  - Excellent browser console override system (minimal changes needed)
  - Trace correlation ID system (works well across systems)
  - Multi-system logging concept (browser + Convex integration)

- **Components to Replace**:
  - All Convex-based rate limiting and storage functions
  - Database-dependent log correlation engine
  - Real-time admin monitoring (moving to on-demand model)

### Data Models

From [Source: architecture/data-models.md#log_entries] and technical guide analysis:

**New Redis Data Structure**:

```typescript
// Redis Key Pattern: logs:{trace_id}
interface RedisLogEntry {
  id: string; // Unique log entry ID
  trace_id: string; // Correlation identifier
  user_id?: string; // User context
  system: 'browser' | 'convex' | 'worker' | 'manual';
  level: 'log' | 'info' | 'warn' | 'error';
  message: string; // Log message content
  stack?: string; // Stack trace if error
  timestamp: number; // Unix timestamp
  context?: Record<string, any>; // Additional metadata
}
```

**Tables to Remove**:

- `rate_limit_state` - Replace with Worker memory/Durable Objects
- `message_fingerprints` - Remove duplicate detection complexity
- `log_queue` - Replace with Redis list operations
- `recent_log_entries` - Replace with on-demand Redis fetching

### API Specifications

From [Source: architecture/api-implementation-details.md] and worker architecture:

**New Worker Endpoints**:

```typescript
// POST /log - Main log ingestion endpoint
interface WorkerLogRequest {
  trace_id: string;
  message: string;
  level: 'log' | 'info' | 'warn' | 'error';
  system?: 'browser' | 'convex' | 'worker'; // Auto-detected if not provided
  context?: Record<string, any>;
  user_id?: string;
}

// Response: 200 OK or 429 Rate Limited
interface WorkerLogResponse {
  success: boolean;
  trace_id: string;
  remaining_quota?: number;
  error?: string;
}
```

**Upstash Redis Operations**:

```typescript
// Store log entry with TTL
LPUSH logs:${trace_id} ${JSON.stringify(logEntry)}
EXPIRE logs:${trace_id} 3600  // 1 hour TTL

// Fetch logs for debugging
LRANGE logs:${trace_id} 0 -1  // Get all logs for trace
```

### Component Specifications

From [Source: architecture/source-tree.md] and worker technical guide:

**New Worker Structure**:

```
apps/workers/log-ingestion/
├── src/
│   ├── index.ts           # Main worker entry point
│   ├── rate-limiter.ts    # Worker-based rate limiting
│   ├── redis-client.ts    # Upstash Redis integration
│   ├── log-processor.ts   # Log validation and processing
│   └── types.ts           # Shared type definitions
├── wrangler.toml          # Cloudflare Worker configuration
├── package.json           # Worker dependencies
└── tsconfig.json          # TypeScript configuration
```

**Updated Browser Integration**:

- File: `apps/web/lib/console-override.ts`
- Change: Update endpoint to Worker URL (minimal changes)
- Preserve: All existing logic (trace IDs, rate limiting, noise suppression)

### File Locations

Based on [Source: architecture/source-tree.md] and infrastructure patterns:

**New Files**:

- `apps/workers/log-ingestion/src/index.ts` - Main Worker entry point
- `apps/workers/log-ingestion/wrangler.toml` - Worker configuration
- `apps/workers/log-ingestion/package.json` - Worker dependencies
- `apps/convex/internalLogging.ts` - New Convex -> Worker bridge

**Files to Remove**:

- `apps/convex/rateLimiter.ts` - Replace with Worker-based limiting
- `apps/convex/logCorrelation.ts` - Replace with on-demand fetching
- `apps/convex/cleanup.ts` - Redis TTL handles cleanup automatically
- `apps/convex/monitoring.ts` - Replace with simpler Worker metrics

**Files to Update**:

- `apps/web/lib/console-override.ts` - Change endpoint URL only
- `apps/convex/schema.ts` - Remove logging table definitions
- Root `package.json` - Add Worker deployment scripts
- `turbo.json` - Add Worker tasks

### Testing Requirements

From [Source: docs/testing/technical/test-strategy-and-standards.md]:

**Worker Testing Strategy**:

- Unit tests for rate limiting logic using Jest
- Integration tests for Redis operations with test Redis instance
- E2E tests for multi-system log ingestion workflow
- Load testing for rate limiting under burst conditions

**Test File Structure**:

- `tests/workers/log-ingestion/` - Worker unit tests
- `tests/e2e/logging-v2.spec.ts` - End-to-end Worker integration
- `tests/config/redis-test-setup.js` - Redis testing utilities

### Technical Constraints

From [Source: architecture/tech-stack.md] and infrastructure requirements:

**Cloudflare Worker Constraints**:

- TypeScript support with modern ES modules
- 128MB memory limit for rate limiting data structures
- 10ms CPU time limit per request (efficient processing required)
- Environment variables for Upstash Redis connection

**Upstash Redis Specifications**:

- REST API integration (no persistent connections)
- 1-hour TTL for automatic cleanup
- Cost optimization: ~$0.2 per 100K requests
- Maximum 1MB per Redis key (batch size limits)

**Monorepo Integration**:

- Turbo task coordination for parallel development
- Shared TypeScript configuration inheritance
- Consistent linting and formatting across all packages

### Cost Constraint Integration

From technical guide analysis:

**New Cost Model**:

- **Upstash Redis**: ~$2/month for 50K logs
- **Worker Requests**: Included in Cloudflare free tier for development
- **Total Estimated**: ~$2/month vs current $10/month (80% reduction)

**Rate Limiting Strategy**:

- Global limit: 1000 logs/hour total
- System quotas: Browser 40%, Convex 30%, Worker 30%
- Per-trace limit: 100 logs/hour per trace_id
- Burst handling: Worker memory buffers for temporary spikes

### Security Considerations

From [Source: architecture/security.md]:

**Worker Security**:

- CORS configuration for multi-origin log sources
- Rate limiting prevents abuse and cost attacks
- Environment variable protection for Redis credentials
- Input validation and sanitization for all log data

**Redis Security**:

- Upstash provides built-in encryption and access control
- REST API authentication via Bearer tokens
- Automatic TTL prevents long-term data exposure
- No persistent sensitive data storage

## Pattern Validation

### Testing Standards

From [Source: docs/testing/technical/test-strategy-and-standards.md]:

**Worker Testing Patterns**:

- Jest unit tests with `@cloudflare/workers-types` for Worker environment
- Miniflare for local Worker testing and development
- Integration@ tests with actual Redis instance for reliable testing
- E2E tests covering full browser → Worker → Redis → fetching workflow

**Test Coverage Requirements**:

- 85% coverage for Worker logic (rate limiting, processing, Redis integration)
- Integration tests for all three log sources (browser, Convex, workers)
- Load testing for burst scenarios and rate limiting effectiveness

### Pattern Compliance

Must follow established infrastructure patterns:

**Monorepo Patterns**:

- Turbo task coordination following existing `apps/web` and `apps/convex` structure
- Shared configuration inheritance from root-level configs
- Consistent package.json scripts and dependency management

**Deployment Patterns**:

- Wrangler CLI integration following Cloudflare deployment standards
- Environment-specific configuration (development/production)
- CI/CD integration with existing GitHub Actions workflow

**Error Handling Patterns**:

- Graceful fallbacks when Redis is unavailable
- Proper HTTP status codes and error responses
- Correlation ID preservation for debugging failed requests

## Change Log

| Date       | Version | Description                 | Author                          |
| ---------- | ------- | --------------------------- | ------------------------------- |
| 2025-01-29 | 1.0     | Initial story draft created | Claude (create-next-story task) |
